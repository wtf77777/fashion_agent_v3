"""
AI æœå‹™å±¤ - Oreoooooo çµ‚æ¥µç©©å®šæ•´åˆç‰ˆ
è™•ç†æ‰€æœ‰èˆ‡ Gemini API ç›¸é—œçš„æ¥­å‹™é‚è¼¯ï¼ŒåŒ…å«é‡è©¦æ©Ÿåˆ¶ã€é«˜å“è³ª Prompt èˆ‡éšæ¢¯å¼è¾¨è­˜
"""
import json
import time
import google.generativeai as genai
from typing import List, Dict, Optional, Tuple
from database.models import ClothingItem, WeatherData

from google.api_core.exceptions import ResourceExhausted, InternalServerError
from api.model_a_adapter import ModelAAdapter
from api.recommendation_engine import RecommendationEngine

class AIService:
    def __init__(self, api_key: str, rate_limit_seconds: int = 15):
        self.api_key = api_key
        self.rate_limit_seconds = rate_limit_seconds
        self.last_request_time = 0
        genai.configure(api_key=api_key)
        
        # è¨­å®šå®‰å…¨éæ¿¾ (é—œé–‰ä»¥é¿å…èª¤åˆ¤è¡£ç‰©åœ–ç‰‡)
        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]
        
        # ä¾ç…§ Oreoooooo è¦æ±‚ï¼Œå®šç¾©éšæ¢¯æ¨¡å‹ (Tier 1 & Tier 2)
        # æ³¨æ„: ç¢ºä¿ç³»çµ±ç’°å¢ƒæ”¯æ´æ­¤æ¨¡å‹åç¨±
        self.model_t1 = genai.GenerativeModel('gemini-2.5-flash', safety_settings=self.safety_settings)
        self.model_t2 = genai.GenerativeModel('gemini-3-flash-preview', safety_settings=self.safety_settings)
    
    def _rate_limit_wait(self):
        """API é€Ÿç‡é™åˆ¶ä¿è­· - åš´æ ¼ç‰ˆ"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.rate_limit_seconds:
            wait_time = self.rate_limit_seconds - time_since_last
            print(f"[AI] â³ é€Ÿç‡é™åˆ¶ä¿è­·ä¸­ï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
            time.sleep(wait_time)
        
        self.last_request_time = time.time()

    def batch_auto_tag(self, img_bytes_list: List[bytes]) -> Optional[List[Dict]]:
        """
        Oreoooooo éšæ¢¯å¼è‡ªå‹•æ¨™ç±¤è¾¨è­˜:
        1. å…ˆå˜—è©¦ Gemini 2.5-flash (å…·å‚™é‡è©¦)
        2. è‹¥çˆ†æµé‡å‰‡è©¦ Gemini 3-flash-preview (å…·å‚™é‡è©¦)
        3. å‡å¤±æ•—å‰‡ Fallback åˆ°æœ¬åœ° Model A
        """
        print(f"[AI] é–‹å§‹å° {len(img_bytes_list)} ä»¶è¡£ç‰©é€²è¡Œéšæ¢¯å¼è¾¨è­˜åˆ†æ...")
        
        # A. å˜—è©¦æ¨¡å‹ 1 (2.5-flash)
        results = self._call_gemini_with_robust_logic(self.model_t1, img_bytes_list, "Tier 1 (2.5-flash)")
        if results: return results
        
        # B. å˜—è©¦æ¨¡å‹ 2 (3-preview)
        results = self._call_gemini_with_robust_logic(self.model_t2, img_bytes_list, "Tier 2 (3-preview)")
        if results: return results

        # C. æœ€çµ‚ Fallback - æœ¬åœ° Model A (ç•¶ API å‡ä¸å¯ç”¨æ™‚)
        print("[AI] âš ï¸ æ‰€æœ‰ Gemini æ¨¡å‹å‡å·²é”æµé‡ä¸Šé™æˆ–å¤±æ•—ï¼Œå•Ÿå‹•æœ¬åœ° Model A è¾¨è­˜...")
        adapter = ModelAAdapter()
        final_results = []
        for idx, img_bytes in enumerate(img_bytes_list):
            local_result = adapter.analyze_image(img_bytes)
            if local_result:
                final_results.append({
                    "name": f"{local_result['colors'][0]} {local_result['category_zh']}" if local_result['colors'] else local_result['category_zh'],
                    "category": self._map_category_to_frontend(local_result['category']),
                    "color": local_result['colors'][0] if local_result['colors'] else "æœªçŸ¥",
                    "style": local_result['style'][0] if local_result['style'] else "ä¼‘é–’"
                })
            else:
                final_results.append({"name": f"æœªçŸ¥è¡£ç‰© {idx+1}", "category": "ä¸Šè¡£", "color": "æœªçŸ¥", "style": "ä¼‘é–’"})
        
        print(f"[AI] âœ… å›æ­¸æœ¬åœ° Model Aè¾¨è­˜å®Œæˆ ({len(final_results)} ä»¶)")
        return final_results

    def _call_gemini_with_robust_logic(self, model, img_bytes_list, label) -> Optional[List[Dict]]:
        """åŸæœ¬æœ€ç©©å¥çš„å‘¼å«é‚è¼¯ (åŒ…å« Retry, JSON æ¸…æ´—, Candidates æª¢æŸ¥)"""
        try:
            self._rate_limit_wait()
            print(f"[AI] ğŸš€ æ­£åœ¨å˜—è©¦ {label}...")

            # è£œå›æœ€é«˜å“è³ªçš„ Prompt
            prompt = f"""è«‹ä»”ç´°åˆ†æé€™ {len(img_bytes_list)} ä»¶è¡£æœ,ç‚ºæ¯ä»¶è¡£æœåˆ†åˆ¥å›å‚³ JSON æ ¼å¼çš„æ¨™ç±¤ã€‚
 
å›å‚³æ ¼å¼å¿…é ˆæ˜¯ä¸€å€‹ JSON é™£åˆ—,åŒ…å« {len(img_bytes_list)} å€‹ç‰©ä»¶:
[
  {{
    "name": "è¡£æœåç¨±(å¦‚:ç™½è‰²Tæ¤ã€ç‰›ä»”è¤²)",
    "category": "ä¸Šè¡£|ä¸‹èº«|å¤–å¥—|é‹å­|é…ä»¶",
    "color": "ä¸»è¦é¡è‰²",
    "style": "é¢¨æ ¼(å¦‚:ä¼‘é–’ã€æ­£å¼ã€é‹å‹•)"
  }},
  ... (ä¾åºå°æ‡‰æ¯å¼µåœ–ç‰‡)
]
 
é‡è¦è¦å‰‡:
1. åªå›å‚³ JSON é™£åˆ—,ä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—
2. ä¸è¦åŒ…å« ```json æˆ–ä»»ä½• Markdown æ¨™ç±¤
3. é™£åˆ—ä¸­çš„é †åºå¿…é ˆèˆ‡åœ–ç‰‡é †åºä¸€è‡´
4. æ¯å€‹ç‰©ä»¶éƒ½å¿…é ˆåŒ…å«é€™ 4 å€‹æ¬„ä½
"""
            content_parts = [{"mime_type": "image/jpeg", "data": img} for img in img_bytes_list]
            content_parts.insert(0, prompt)

            max_retries = 3
            retry_count = 0
            while retry_count < max_retries:
                try:
                    response = model.generate_content(content_parts)
                    return self._parse_and_validate_response(response, len(img_bytes_list))
                except ResourceExhausted:
                    retry_count += 1
                    wait_time = 30 * retry_count
                    print(f"[AI] âš ï¸ {label} é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦ ({retry_count}/{max_retries})...")
                    time.sleep(wait_time)
                except Exception as e:
                    print(f"[AI] {label} å‘¼å«ç•°å¸¸: {e}")
                    break
            return None
        except Exception as e:
            print(f"[AI] {label} å€å¡ŠåŸ·è¡Œå¤±æ•—: {e}")
            return None

    def _parse_and_validate_response(self, response, count):
        """åŸæœ¬ä»£ç¢¼ä¸­æœ€å®Œæ•´çš„è§£æé‚è¼¯"""
        try:
            # æª¢æŸ¥æ˜¯å¦å­˜åœ¨ content
            try:
                raw_text = response.text
            except ValueError:
                if response.candidates and response.candidates[0].content.parts:
                    raw_text = response.candidates[0].content.parts[0].text
                else:
                    return None
            
            clean_text = raw_text.strip().replace('```json', '').replace('```', '').strip()
            data = json.loads(clean_text)
            
            if isinstance(data, list) and len(data) == count:
                return data
            return None
        except:
            return None

    def generate_outfit_recommendation(
        self, wardrobe: List[ClothingItem], weather: WeatherData, style: str, occasion: str
    ) -> Optional[Dict]:
        """ç”¢å‡ºæ™ºèƒ½ç©¿æ­çµ„åˆ - å«å®Œæ•´è§£æèˆ‡ Gemini çµèª"""
        try:
            self._rate_limit_wait()
            # 1. æ„åœ–è§£æ
            analysis_prompt = f"""
            ä½¿ç”¨è€…æè¿°ï¼š"{occasion}ï½œé¢¨æ ¼åå¥½ï¼š{style}"
            è«‹è§£æå ´æ™¯æ„åœ–èˆ‡å¤©æ°£å½±éŸ¿({weather.temp}åº¦)ã€‚
            å›å‚³ JSON: {{
                "normalized_occasion": "ç´„æœƒ|æ—¥å¸¸|é‹å‹•|ä¸Šç­|æ­£å¼",
                "needs_outer": bool,
                "vibe_description": "ä¸€æ®µå°ˆç‚ºä½¿ç”¨è€…å¯«çš„ 30 å­—é–‹å ´",
                "parsed_style": "æ ¸å¿ƒé¢¨æ ¼æ¨™ç±¤"
            }}
            """
            res = self.model_t1.generate_content(analysis_prompt)
            analysis = json.loads(res.text.strip().replace('```json','').replace('```',''))
            
            # 2. å¼•æ“å¾çœŸå¯¦è¡£æ«¥æŒ‘é¸
            engine = RecommendationEngine()
            outfits = engine.recommend(
                wardrobe, weather, analysis["normalized_occasion"], "ä¸­æ€§", 
                analysis["parsed_style"], analysis["needs_outer"]
            )
            
            if not outfits: return None

            # 3. é‡å°å…·é«”è¡£æœç”¢å‡º 80 å­—æº«é¦¨ç¸½çµ (Gemini çµèª)
            detail_prompt = f"é‡å°ä»¥ä¸‹é€™ 3 å¥—å¾è¡£æ«¥æŒ‘å‡ºçš„æ–¹æ¡ˆï¼Œå¯«ä¸€æ®µç´„ 80 å­—çš„é¡§å•è©±èªçµ¦ä½¿ç”¨è€…ï¼Œè§£é‡‹é€™å¹¾å¥—ç‚ºä½•é©åˆä»Šå¤©({weather.temp}åº¦)åŠ{occasion}ï¼š\n"
            for i, o in enumerate(outfits):
                names = [f"{it['color']}{it['name']}" for it in o['items']]
                detail_prompt += f"æ–¹æ¡ˆ{i+1}: {', '.join(names)}\n"
            
            self._rate_limit_wait()
            reason_res = self.model_t1.generate_content(detail_prompt)
            
            return {
                "vibe": analysis["vibe_description"],
                "detailed_reasons": reason_res.text,
                "recommendations": outfits
            }
        except Exception as e:
            print(f"[AI Recommendation Error] {e}")
            return None

    def _map_category_to_frontend(self, model_cat: str) -> str:
        """å°‡ Model A çš„é¡åˆ¥å°æ‡‰åˆ°å‰ç«¯ (Oreoooooo æŒ‡å®šå®Œæ•´ç‰ˆ)"""
        UPPER = ['Tee', 'Blouse', 'Top', 'Tank', 'Jersey', 'Hoodie', 'Sweater']
        LOWER = ['Jeans', 'Shorts', 'Skirt', 'Sweatpants', 'Joggers', 'Leggings', 'Chinos']
        OUTER = ['Jacket', 'Coat', 'Blazer', 'Cardigan', 'Parka', 'Kimono']
        FULL = ['Dress', 'Jumpsuit', 'Romper']
        
        if model_cat in UPPER: return "ä¸Šè¡£"
        if model_cat in LOWER: return "ä¸‹èº«"
        if model_cat in OUTER: return "å¤–å¥—"
        if model_cat in FULL: return "ä¸Šè¡£"
        return "é…ä»¶"

    def parse_recommended_items(self, ai_response: str, wardrobe: List[ClothingItem]) -> List[ClothingItem]:
        """ä¿ç•™è§£æå‡½æ•¸ä»¥æ”¯æ´ä¸»æµç¨‹"""
        recommended_items = []
        res = str(ai_response).lower()
        for item in wardrobe:
            if (item.name and item.name.lower() in res) or \
               (f"{item.color}{item.category}".lower() in res.replace(' ', '')):
                recommended_items.append(item)
        return recommended_items
