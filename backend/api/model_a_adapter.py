import sys
from pathlib import Path
from PIL import Image
import io
import torch
import logging

# åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° sys.pathï¼Œç¢ºä¿èƒ½ import model_a
BASE_DIR = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(BASE_DIR))

try:
    from model_a.inference import FashionPredictor
    MODEL_A_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Model A import failed: {e}")
    MODEL_A_AVAILABLE = False

logger = logging.getLogger(__name__)

class ModelAAdapter:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ModelAAdapter, cls).__new__(cls)
            cls._instance._initialize()
        return cls._instance
    
    def _initialize(self):
        self.predictor = None
        if not MODEL_A_AVAILABLE:
            logger.warning("Model A module not found.")
            return

        # æ¨¡å‹æ¬Šé‡è·¯å¾‘
        # å„ªå…ˆå°‹æ‰¾æœ€ä½³æ¨¡å‹
        checkpoint_dir = BASE_DIR / "model_a" / "output" / "checkpoints"
        checkpoint_path = checkpoint_dir / "best.pth"
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦åˆä½µæª”æ¡ˆ (é‡å° GitHub ä¸Šå‚³é™åˆ¶)
        if not checkpoint_path.exists():
            parts = sorted(checkpoint_dir.glob("best.pth.part*"))
            if parts:
                logger.info(f"ğŸ§© Found {len(parts)} parts, merging model...")
                try:
                    with open(checkpoint_path, 'wb') as outfile:
                        for part in parts:
                            with open(part, 'rb') as infile:
                                outfile.write(infile.read())
                    logger.info("âœ… Model merged successfully.")
                except Exception as e:
                    logger.error(f"âŒ Failed to merge model parts: {e}")

        if checkpoint_path.exists():
            try:
                # è¼‰å…¥æ¨¡å‹ (é€™è£¡æœƒè‡ªå‹•ä½¿ç”¨ GPU æˆ– CPU)
                self.predictor = FashionPredictor(str(checkpoint_path))
                logger.info(f"âœ… Model A loaded from {checkpoint_path}")
            except Exception as e:
                logger.error(f"âŒ Failed to load Model A: {e}")
                self.predictor = None
        else:
            logger.warning(f"âš ï¸ Model A checkpoint not found at {checkpoint_path}")
            self.predictor = None

    def analyze_image(self, image_bytes: bytes):
        """
        åˆ†æåœ–ç‰‡ä¸¦è¿”å›çµæ§‹åŒ–ç‰¹å¾µ
        
        Returns:
            dict: {
                "category": str,
                "attributes": list[str],
                "colors": list[str], # Hex codes
                "style": list[str],
                "confidence": float
            }
        """
        if not self.predictor:
            return None
            
        try:
            # å°‡ bytes è½‰æ›ç‚º PIL Image
            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            # å„²å­˜ç‚ºæš«å­˜æª”ä¾›æ¨è«–ä½¿ç”¨ (inference.py è¨­è¨ˆæ˜¯ç”¨è·¯å¾‘è®€å–)
            # ç‚ºäº†æ•ˆèƒ½ï¼Œæˆ‘å€‘ç¨å¾Œæ‡‰è©²ä¿®æ”¹ inference.py æ”¯æ´ç›´æ¥å‚³å…¥ PIL Image
            # ä½†ç¾åœ¨å…ˆç”¨æœ€ç°¡å–®çš„æ–¹æ³•: æ”¹å¯« inference.py çš„ä»‹é¢
            
            # ä½¿ç”¨æˆ‘å€‘ä¿®æ”¹éå¾Œçš„ predictor.predict_from_image (ç¨å¾Œéœ€è¦åœ¨ inference.py ä¸­å¢åŠ æ­¤æ–¹æ³•)
            # æˆ–è€…ç›´æ¥ä¿®æ”¹ inference.py è®“ predict æ¥å— PIL Image
            
            # é€™è£¡æˆ‘å€‘éœ€è¦å° inference.py åšä¸€é»å°ä¿®æ”¹ä¾†æ”¯æ´ memory image
            # æš«æ™‚å…ˆæŠŠ PIL image å‚³éå»ï¼Œå‡è¨­æˆ‘å€‘æœƒä¿®æ”¹ inference.py
            
            # å‘¼å«é æ¸¬ (æ³¨æ„ï¼šé€™è£¡å‡è¨­ predict å·²ç¶“è¢«ä¿®æ”¹ç‚ºæ”¯æ´ PIL Image æˆ–æˆ‘å€‘éœ€è¦ä¿®æ”¹å®ƒ)
            # ç‚ºäº†ä¸æ”¹å‹•å¤ªå¤š model_a çš„ä»£ç¢¼ï¼Œæˆ‘å€‘å…ˆç”¨è‡¨æ™‚æ–‡ä»¶çš„æ–¹æ³• (é›–ç„¶æ…¢ä¸€é»ä½†æœ€ç©©)
            import tempfile
            with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
                image.save(tmp.name)
                tmp_path = tmp.name
            
            result = self.predictor.predict(tmp_path, top_k=3)
            
            # æ¸…ç†æš«å­˜æª”
            Path(tmp_path).unlink()
            
            # æ ¼å¼åŒ–è¼¸å‡º
            return self._format_result(result)
            
        except Exception as e:
            logger.error(f"âŒ Model A inference error: {e}")
            return None

    def _format_result(self, raw_result):
        """å°‡ Model A çš„åŸå§‹è¼¸å‡ºè½‰æ›ç‚ºå‰ç«¯éœ€è¦çš„æ ¼å¼"""
        
        # é¡åˆ¥ (Category)
        category = raw_result['category']['top_1']['name']
        confidence = raw_result['category']['top_1']['probability']
        
        # å±¬æ€§ (Attributes)
        attributes = [attr['name'] for attr in raw_result['attributes']]
        
        # é¡è‰² (Colors) - åªå–å‰ 2 å€‹ä¸»è¦é¡è‰²çš„ Hex
        colors = [c['hex'] for c in raw_result['colors'][:2]]
        
        # é¢¨æ ¼ (Style)
        style = raw_result['style_tags']
        
        # æ“´å……å±¬æ€§ï¼šå¦‚æœä¿¡å¿ƒåº¦å¤ é«˜ï¼ŒæŠŠé¡åˆ¥ä¹ŸåŠ åˆ°å±¬æ€§æ¨™ç±¤è£¡ï¼Œæ–¹ä¾¿æœå°‹
        if confidence > 0.6:
            attributes.append(category)
            
        return {
            "category": category,
            "category_zh": translate_category(category), # éœ€è¦ä¸€å€‹ç¿»è­¯å‡½æ•¸
            "attributes": attributes,
            "colors": colors,
            "style": style,
            "confidence": confidence,
            "source": "model_a" # æ¨™è¨˜ä¾†æº
        }

# ç°¡å–®çš„ç¿»è­¯å°ç…§è¡¨ (DeepFashion -> ä¸­æ–‡)
def translate_category(eng_name):
    MAPPING = {
        'Dress': 'é€£èº«è£™', 'Tee': 'Tæ¤', 'Blouse': 'å¥³å¼è¥¯è¡«', 'Top': 'ä¸Šè¡£',
        'Shorts': 'çŸ­è¤²', 'Skirt': 'è£™å­', 'Jeans': 'ç‰›ä»”è¤²', 'Jacket': 'å¤¾å…‹',
        'Cardigan': 'é‡ç¹”å¤–å¥—', 'Coat': 'å¤§è¡£', 'Sweater': 'æ¯›è¡£', 'Hoodie': 'å¸½T',
        'Tank': 'èƒŒå¿ƒ', 'Joggers': 'æ…¢è·‘è¤²', 'Leggings': 'ç·Šèº«è¤²',
        # ... å…¶ä»–é¡åˆ¥
    }
    return MAPPING.get(eng_name, eng_name)
